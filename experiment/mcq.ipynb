{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7ddfc262",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e31c9936",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ccf1f624",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4bde9884",
   "metadata": {},
   "outputs": [],
   "source": [
    "key=os.getenv(\"openai_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fbb7c372",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIF\\AppData\\Local\\Temp\\ipykernel_8924\\3734199289.py:1: LangChainDeprecationWarning: The class `ChatOpenAI` was deprecated in LangChain 0.0.10 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-openai package and should be used instead. To use it run `pip install -U :class:`~langchain-openai` and import as `from :class:`~langchain_openai import ChatOpenAI``.\n",
      "  llm=ChatOpenAI(openai_api_key=key, model_name='gpt-3.5-turbo', temperature=0.5)\n"
     ]
    }
   ],
   "source": [
    "llm=ChatOpenAI(openai_api_key=key, model_name='gpt-3.5-turbo', temperature=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "062e79d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5b7601a",
   "metadata": {},
   "source": [
    "### Input Prompt Template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76991a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Response_Json={\n",
    "    '1':{\n",
    "        'mcq':'multiple choice question',\n",
    "        'options':{\n",
    "            'a':'choice here',\n",
    "            'b':'choice here',\n",
    "            'c':'choice here',\n",
    "            'd':'choice here'\n",
    "        },\n",
    "        'correct':'correct answer',\n",
    "    },\n",
    "    '2':{\n",
    "        'mcq':'multiple choice question',\n",
    "        'options':{\n",
    "            'a':'choice here',\n",
    "            'b':'choice here',\n",
    "            'c':'choice here',\n",
    "            'd':'choice here'\n",
    "        },\n",
    "        'correct':'correct answer',\n",
    "    },\n",
    "    '3':{\n",
    "        'mcq':'multiple choice question',\n",
    "        'options':{\n",
    "            'a':'choice here',\n",
    "            'b':'choice here',\n",
    "            'c':'choice here',\n",
    "            'd':'choice here'\n",
    "        },\n",
    "        'correct':'correct answer',\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c242c722",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE=\"\"\"\n",
    "Text : {text}\n",
    "You are an expert mcq maker. Given the above text, it is your job to \\\n",
    "create a quiz of {number} multiple choices questions for {subject} students in {tone} tone.\n",
    "make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
    "make sure to format your response like RESPONSE_JSON below and use it as guide. \\\n",
    "Ensure to make {number} mcqs.\n",
    "### RESPONSE_JSON\n",
    "{Response_Json}\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f8d6ef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=['text','number', 'subject', 'tone', 'Response_Json'],\n",
    "    template=TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea959cf9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIF\\AppData\\Local\\Temp\\ipykernel_8924\\2748869412.py:3: LangChainDeprecationWarning: The class `LLMChain` was deprecated in LangChain 0.1.17 and will be removed in 1.0. Use :meth:`~RunnableSequence, e.g., `prompt | llm`` instead.\n",
      "  quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key='quiz', verbose=True)\n"
     ]
    }
   ],
   "source": [
    "from env.Lib.tabnanny import verbose\n",
    "\n",
    "quiz_chain=LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key='quiz', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f9a6340a",
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE2=\"\"\"\n",
    "you are an expert English grammarian and writer. Given a multiple choice quiz for {subject} students. \\\n",
    "you need to evaluate the complexity of questions and give a complete analysis of quiz.only use at max 50 words for complexity.\n",
    "if the quiz is not as per with the cognitive and analytical abilities of the students. \\\n",
    "Update the quiz questions wich needs to be changed and change the tone such that it perfectly fits the students ability.\n",
    "Quiz_MCQs.\n",
    "{quiz}\n",
    "\n",
    "Check from an expert English Writer of the above quiz:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51b7e95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt=PromptTemplate(\n",
    "    input_variables=['subject','quiz'],\n",
    "    template=TEMPLATE2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8b5abd92",
   "metadata": {},
   "outputs": [],
   "source": [
    "review_chain=LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key='review', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d9caf957",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_evaluate_chain=SequentialChain(chains=[quiz_chain,review_chain],input_variables=['text','number', 'subject', 'tone', 'Response_Json'],\n",
    "                                        output_variables=['quiz','review'], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "51764f47",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path=r\"C:\\Users\\ASIF\\mcqgen\\data.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb1a6455",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Bidirectional Encoders (NSP)\n",
      " • An important class of applications involves determining the relationship between\n",
      " pairs of sentences– paraphrase detection (detecting if two sentences have similar meanings)– entailment (detecting if the meanings of two sentences entail or contradict each other)– discourse coherence (deciding if two neighboring sentences form a coherent discourse)\n",
      " • To capture the kind of knowledge required for applications such as these, BERT\n",
      " introduced a second learning objective called Next Sentence Prediction (NSP)\n",
      " • Training: The model is presented with pairs of sentences and is asked to predict\n",
      " whether each pair consists of an actual pair of adjacent sentences from the training\n",
      " corpus or a pair of unrelated sentences.\n",
      " • In BERT, 50% of the training pairs consisted of positive pairs, and in the other 50%\n",
      " the second sentence of a pair was randomly selected from elsewhere in the corpus– TheNSPloss is based on how well the model can distinguish true pairs from random pairs\n",
      " • BERTintroduces two new tokens to the input representation– After tokenizing the input with the subword model, the token [CLS] is prepended to the\n",
      " input sentence pair, and the token [SEP] is placed between the sentences and after the\n",
      " final token of the second sentence– During training, the output vector from the final layer associated with the [CLS] token\n",
      " represents the next sentence prediction\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open(file_path,'r') as file:\n",
    "    Text=file.read()\n",
    "    \n",
    "print(Text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d27e5980",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Serialize the py dict into a json-formatted string\n",
    "json.dumps(Response_Json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8270b9ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "Number  =5\n",
    "Subject ='BERT'\n",
    "Tone    ='Simple'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d4e8309",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ASIF\\AppData\\Local\\Temp\\ipykernel_8924\\112805976.py:4: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  response=generate_evaluate_chain(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Text : Training Bidirectional Encoders (NSP)\n",
      " • An important class of applications involves determining the relationship between\n",
      " pairs of sentences– paraphrase detection (detecting if two sentences have similar meanings)– entailment (detecting if the meanings of two sentences entail or contradict each other)– discourse coherence (deciding if two neighboring sentences form a coherent discourse)\n",
      " • To capture the kind of knowledge required for applications such as these, BERT\n",
      " introduced a second learning objective called Next Sentence Prediction (NSP)\n",
      " • Training: The model is presented with pairs of sentences and is asked to predict\n",
      " whether each pair consists of an actual pair of adjacent sentences from the training\n",
      " corpus or a pair of unrelated sentences.\n",
      " • In BERT, 50% of the training pairs consisted of positive pairs, and in the other 50%\n",
      " the second sentence of a pair was randomly selected from elsewhere in the corpus– TheNSPloss is based on how well the model can distinguish true pairs from random pairs\n",
      " • BERTintroduces two new tokens to the input representation– After tokenizing the input with the subword model, the token [CLS] is prepended to the\n",
      " input sentence pair, and the token [SEP] is placed between the sentences and after the\n",
      " final token of the second sentence– During training, the output vector from the final layer associated with the [CLS] token\n",
      " represents the next sentence prediction\n",
      "\n",
      "You are an expert mcq maker. Given the above text, it is your job to create a quiz of 5 multiple choices questions for BERT students in Simple tone.\n",
      "make sure the questions are not repeated and check all the questions to be conforming the text as well.\n",
      "make sure to format your response like RESPONSE_JSON below and use it as guide. Ensure to make 5 mcqs.\n",
      "### RESPONSE_JSON\n",
      "{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}\n",
      "\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
      "Prompt after formatting:\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "you are an expert English grammarian and writer. Given a multiple choice quiz for BERT students. you need to evaluate the complexity of questions and give a complete analysis of quiz.only use at max 50 words for complexity.\n",
      "if the quiz is not as per with the cognitive and analytical abilities of the students. Update the quiz questions wich needs to be changed and change the tone such that it perfectly fits the students ability.\n",
      "Quiz_MCQs.\n",
      "{\n",
      "\"1\": {\n",
      "\"mcq\": \"What is the purpose of the Next Sentence Prediction (NSP) task in BERT training?\",\n",
      "\"options\": {\"a\": \"To predict the next word in a sentence\", \"b\": \"To determine if two sentences have similar meanings\", \"c\": \"To classify images in a dataset\", \"d\": \"To generate new text based on input\"},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"2\": {\n",
      "\"mcq\": \"How is the NSP loss calculated in BERT training?\",\n",
      "\"options\": {\"a\": \"Based on the length of the input sentences\", \"b\": \"Based on the model's ability to distinguish true pairs from random pairs\", \"c\": \"Based on the number of layers in the model\", \"d\": \"Based on the learning rate of the optimizer\"},\n",
      "\"correct\": \"b\"\n",
      "},\n",
      "\"3\": {\n",
      "\"mcq\": \"What tokens are introduced to the input representation in BERT for NSP?\",\n",
      "\"options\": {\"a\": \"[CLS] and [SEP]\", \"b\": \"[START] and [END]\", \"c\": \"[TOKEN] and [MASK]\", \"d\": \"[BEGIN] and [STOP]\"},\n",
      "\"correct\": \"a\"\n",
      "},\n",
      "\"4\": {\n",
      "\"mcq\": \"In BERT training, what does the output vector from the final layer associated with the [CLS] token represent?\",\n",
      "\"options\": {\"a\": \"The first sentence in the pair\", \"b\": \"The second sentence in the pair\", \"c\": \"The next sentence prediction\", \"d\": \"The loss function value\"},\n",
      "\"correct\": \"c\"\n",
      "},\n",
      "\"5\": {\n",
      "\"mcq\": \"What percentage of training pairs in BERT consists of positive pairs for NSP?\",\n",
      "\"options\": {\"a\": \"25%\", \"b\": \"50%\", \"c\": \"75%\", \"d\": \"100%\"},\n",
      "\"correct\": \"b\"\n",
      "}\n",
      "}\n",
      "\n",
      "Check from an expert English Writer of the above quiz:\n",
      "\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "### How to setup token usage tracking in langchain\n",
    "\n",
    "with get_openai_callback() as cb:\n",
    "    response=generate_evaluate_chain(\n",
    "        {\n",
    "            \"text\"         :Text,\n",
    "            \"number\"       :Number,\n",
    "            \"subject\"      :Subject,\n",
    "            \"tone\"         :Tone,\n",
    "            \"Response_Json\":json.dumps(Response_Json)\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a28aee89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total tokens      :  1481\n",
      "prompt tokens     : 1033\n",
      "completion tokens : 448\n",
      "total cost        : 0.0024455\n"
     ]
    }
   ],
   "source": [
    "print('total tokens      : ',cb.total_tokens)\n",
    "print('prompt tokens     :',cb.prompt_tokens)\n",
    "print('completion tokens :',cb.completion_tokens)\n",
    "print('total cost        :',cb.total_cost)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1ba06408",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Training Bidirectional Encoders (NSP)\\n • An important class of applications involves determining the relationship between\\n pairs of sentences– paraphrase detection (detecting if two sentences have similar meanings)– entailment (detecting if the meanings of two sentences entail or contradict each other)– discourse coherence (deciding if two neighboring sentences form a coherent discourse)\\n • To capture the kind of knowledge required for applications such as these, BERT\\n introduced a second learning objective called Next Sentence Prediction (NSP)\\n • Training: The model is presented with pairs of sentences and is asked to predict\\n whether each pair consists of an actual pair of adjacent sentences from the training\\n corpus or a pair of unrelated sentences.\\n • In BERT, 50% of the training pairs consisted of positive pairs, and in the other 50%\\n the second sentence of a pair was randomly selected from elsewhere in the corpus– TheNSPloss is based on how well the model can distinguish true pairs from random pairs\\n • BERTintroduces two new tokens to the input representation– After tokenizing the input with the subword model, the token [CLS] is prepended to the\\n input sentence pair, and the token [SEP] is placed between the sentences and after the\\n final token of the second sentence– During training, the output vector from the final layer associated with the [CLS] token\\n represents the next sentence prediction\\n',\n",
       " 'number': 5,\n",
       " 'subject': 'BERT',\n",
       " 'tone': 'Simple',\n",
       " 'Response_Json': '{\"1\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"2\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}, \"3\": {\"mcq\": \"multiple choice question\", \"options\": {\"a\": \"choice here\", \"b\": \"choice here\", \"c\": \"choice here\", \"d\": \"choice here\"}, \"correct\": \"correct answer\"}}',\n",
       " 'quiz': '{\\n\"1\": {\\n\"mcq\": \"What is the purpose of the Next Sentence Prediction (NSP) task in BERT training?\",\\n\"options\": {\"a\": \"To predict the next word in a sentence\", \"b\": \"To determine if two sentences have similar meanings\", \"c\": \"To classify images in a dataset\", \"d\": \"To generate new text based on input\"},\\n\"correct\": \"b\"\\n},\\n\"2\": {\\n\"mcq\": \"How is the NSP loss calculated in BERT training?\",\\n\"options\": {\"a\": \"Based on the length of the input sentences\", \"b\": \"Based on the model\\'s ability to distinguish true pairs from random pairs\", \"c\": \"Based on the number of layers in the model\", \"d\": \"Based on the learning rate of the optimizer\"},\\n\"correct\": \"b\"\\n},\\n\"3\": {\\n\"mcq\": \"What tokens are introduced to the input representation in BERT for NSP?\",\\n\"options\": {\"a\": \"[CLS] and [SEP]\", \"b\": \"[START] and [END]\", \"c\": \"[TOKEN] and [MASK]\", \"d\": \"[BEGIN] and [STOP]\"},\\n\"correct\": \"a\"\\n},\\n\"4\": {\\n\"mcq\": \"In BERT training, what does the output vector from the final layer associated with the [CLS] token represent?\",\\n\"options\": {\"a\": \"The first sentence in the pair\", \"b\": \"The second sentence in the pair\", \"c\": \"The next sentence prediction\", \"d\": \"The loss function value\"},\\n\"correct\": \"c\"\\n},\\n\"5\": {\\n\"mcq\": \"What percentage of training pairs in BERT consists of positive pairs for NSP?\",\\n\"options\": {\"a\": \"25%\", \"b\": \"50%\", \"c\": \"75%\", \"d\": \"100%\"},\\n\"correct\": \"b\"\\n}\\n}',\n",
       " 'review': 'The complexity of the quiz questions is high for BERT students, as it requires in-depth knowledge of BERT architecture and training tasks. The questions should be simplified to focus on basic concepts and vocabulary. The tone should be adjusted to be more student-friendly and engaging.'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "89409913",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=response.get('quiz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a6249581",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz=json.loads(quiz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "da6efaaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_table_data=[]\n",
    "\n",
    "for key, value in quiz.items():\n",
    "    mcq=value['mcq']\n",
    "    options=\" | \".join(\n",
    "        [\n",
    "            f\"{option}: {option_value}\"\n",
    "            for option, option_value in value['options'].items()\n",
    "        ]\n",
    "    )\n",
    "    correct=value['correct']\n",
    "    quiz_table_data.append({\"MCQ\":mcq, \"Choices\":options, \"correct_Ans\":correct})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "f76d7493",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'MCQ': 'What is the purpose of the Next Sentence Prediction (NSP) task in BERT training?',\n",
       "  'Choices': 'a: To predict the next word in a sentence | b: To determine if two sentences have similar meanings | c: To classify images in a dataset | d: To generate new text based on input',\n",
       "  'correct_Ans': 'b'},\n",
       " {'MCQ': 'How is the NSP loss calculated in BERT training?',\n",
       "  'Choices': \"a: Based on the length of the input sentences | b: Based on the model's ability to distinguish true pairs from random pairs | c: Based on the number of layers in the model | d: Based on the learning rate of the optimizer\",\n",
       "  'correct_Ans': 'b'},\n",
       " {'MCQ': 'What tokens are introduced to the input representation in BERT for NSP?',\n",
       "  'Choices': 'a: [CLS] and [SEP] | b: [START] and [END] | c: [TOKEN] and [MASK] | d: [BEGIN] and [STOP]',\n",
       "  'correct_Ans': 'a'},\n",
       " {'MCQ': 'In BERT training, what does the output vector from the final layer associated with the [CLS] token represent?',\n",
       "  'Choices': 'a: The first sentence in the pair | b: The second sentence in the pair | c: The next sentence prediction | d: The loss function value',\n",
       "  'correct_Ans': 'c'},\n",
       " {'MCQ': 'What percentage of training pairs in BERT consists of positive pairs for NSP?',\n",
       "  'Choices': 'a: 25% | b: 50% | c: 75% | d: 100%',\n",
       "  'correct_Ans': 'b'}]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_table_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d6288132",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df=pd.DataFrame(quiz_table_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "79e4e42a",
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_df.to_csv(\"BERT_Quiz.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e6104b4f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MCQ</th>\n",
       "      <th>Choices</th>\n",
       "      <th>correct_Ans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>What is the purpose of the Next Sentence Predi...</td>\n",
       "      <td>a: To predict the next word in a sentence | b:...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>How is the NSP loss calculated in BERT training?</td>\n",
       "      <td>a: Based on the length of the input sentences ...</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>What tokens are introduced to the input repres...</td>\n",
       "      <td>a: [CLS] and [SEP] | b: [START] and [END] | c:...</td>\n",
       "      <td>a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>In BERT training, what does the output vector ...</td>\n",
       "      <td>a: The first sentence in the pair | b: The sec...</td>\n",
       "      <td>c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>What percentage of training pairs in BERT cons...</td>\n",
       "      <td>a: 25% | b: 50% | c: 75% | d: 100%</td>\n",
       "      <td>b</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 MCQ  \\\n",
       "0  What is the purpose of the Next Sentence Predi...   \n",
       "1   How is the NSP loss calculated in BERT training?   \n",
       "2  What tokens are introduced to the input repres...   \n",
       "3  In BERT training, what does the output vector ...   \n",
       "4  What percentage of training pairs in BERT cons...   \n",
       "\n",
       "                                             Choices correct_Ans  \n",
       "0  a: To predict the next word in a sentence | b:...           b  \n",
       "1  a: Based on the length of the input sentences ...           b  \n",
       "2  a: [CLS] and [SEP] | b: [START] and [END] | c:...           a  \n",
       "3  a: The first sentence in the pair | b: The sec...           c  \n",
       "4                 a: 25% | b: 50% | c: 75% | d: 100%           b  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quiz_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
